{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook examines and adds context to the many data files supplied in the competition. It includes the original description of it along with examples to better describe the contents and purpose of each.\n\nImport packages:","metadata":{}},{"cell_type":"code","source":"import gresearch_crypto\n\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:03:52.764135Z","iopub.execute_input":"2021-12-20T14:03:52.764501Z","iopub.status.idle":"2021-12-20T14:03:52.833679Z","shell.execute_reply.started":"2021-12-20T14:03:52.764408Z","shell.execute_reply":"2021-12-20T14:03:52.832312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Declare variables:","metadata":{}},{"cell_type":"code","source":"asset_details_filepath = '/kaggle/input/g-research-crypto-forecasting/asset_details.csv'\nex_sample_submission_filepath = '/kaggle/input/g-research-crypto-forecasting/example_sample_submission.csv'\nex_test_filepath = '/kaggle/input/g-research-crypto-forecasting/example_test.csv'\nsupplemental_train_filepath = '/kaggle/input/g-research-crypto-forecasting/supplemental_train.csv'\ntrain_filepath = '/kaggle/input/g-research-crypto-forecasting/train.csv'","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:03:55.916181Z","iopub.execute_input":"2021-12-20T14:03:55.916595Z","iopub.status.idle":"2021-12-20T14:03:55.92133Z","shell.execute_reply.started":"2021-12-20T14:03:55.916563Z","shell.execute_reply":"2021-12-20T14:03:55.920078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import data:","metadata":{}},{"cell_type":"code","source":"asset_details_df = pd.read_csv(asset_details_filepath)\nex_sample_submission_df = pd.read_csv(ex_sample_submission_filepath)\nex_test_df = pd.read_csv(ex_test_filepath)\nsupplemental_train_df = pd.read_csv(supplemental_train_filepath)\ntrain_df = pd.read_csv(train_filepath)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:04:00.284876Z","iopub.execute_input":"2021-12-20T14:04:00.285218Z","iopub.status.idle":"2021-12-20T14:05:11.49714Z","shell.execute_reply.started":"2021-12-20T14:04:00.285184Z","shell.execute_reply":"2021-12-20T14:05:11.496281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Asset Details Explanation:\n\nThis file is straight forward with the description provided in the competition of:  \n`Provides the real name and of the cryptoasset for each Asset_ID and the weight each cryptoasset receives in the metric.`\n\nWeights are used for calculation of the evaluation metric, where certain coins are more important for the metric than others. See the [tutorial](https://www.kaggle.com/cstein06/tutorial-to-the-g-research-crypto-competition) for a detailed calculation.","metadata":{}},{"cell_type":"code","source":"asset_details_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:05:31.377029Z","iopub.execute_input":"2021-12-20T14:05:31.377369Z","iopub.status.idle":"2021-12-20T14:05:31.400617Z","shell.execute_reply.started":"2021-12-20T14:05:31.377332Z","shell.execute_reply":"2021-12-20T14:05:31.399634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Example Test and Sample Submission Explanation\n\nBoth of these two files have identical descriptions of:  \n`An example of the data that will be delivered by the time series API.`  \nwhere the example sample submission has the additional description of:  \n`The data is just copied from train.csv.`\n\nAlso shown in the above tutorial, these files are examples of what is used during the official submission process. Submission code includes the following parts:\n\n`iter_test = env.iter_test()`\n\n`# get the data for the first test batch`  \n`# this line is indented in a loop in the full code`  \n`(test_df, sample_prediction_df) = next(iter_test)`\n\nIn this example, ex_test_df corresponds to test_df and ex_sample_submission_df corresponds to sample_prediction_df. The test dataframes are new observations to make predictions on, while the prediction dataframes are for storing the predictions once made by models. In fact, the `predict` function is described as:  \n`Stores your predictions for the current batch. Expects the same format as sample_prediction_df.`\nwith the given example of:  \n`env.predict(sample_prediction_df)`","metadata":{}},{"cell_type":"code","source":"ex_test_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:06:06.962679Z","iopub.execute_input":"2021-12-20T14:06:06.963288Z","iopub.status.idle":"2021-12-20T14:06:06.982531Z","shell.execute_reply.started":"2021-12-20T14:06:06.96325Z","shell.execute_reply":"2021-12-20T14:06:06.981584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ex_sample_submission_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:11:55.855177Z","iopub.execute_input":"2021-12-20T14:11:55.856126Z","iopub.status.idle":"2021-12-20T14:11:55.871338Z","shell.execute_reply.started":"2021-12-20T14:11:55.85607Z","shell.execute_reply":"2021-12-20T14:11:55.870487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One point to examine when making actual submissions is that in the tutorial, neither the test or prediction dataframes have a column for group number. However, both provided files have this column as shown above. The test data also has a separate Asset ID column, so group number does not indicate the type of coin, but something else that may or may not be important.\n\n#### Train and Supplemental Train Explanation\n\nThe training file is described succintly as `The training set` while the supplemental training file is given the much longer description of:  \n`After the submission period is over this file's data will be replaced with cryptoasset prices from the submission period. In the Evaluation phase, the train, train supplement, and test set will be contiguous in time, apart from any missing data. The current copy, which is just filled approximately the right amount of data from train.csv is provided as a placeholder.`\n\n","metadata":{}},{"cell_type":"code","source":"train_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:13:55.122188Z","iopub.execute_input":"2021-12-20T14:13:55.123019Z","iopub.status.idle":"2021-12-20T14:13:55.14106Z","shell.execute_reply.started":"2021-12-20T14:13:55.122966Z","shell.execute_reply":"2021-12-20T14:13:55.140067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"supplemental_train_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T14:13:57.433727Z","iopub.execute_input":"2021-12-20T14:13:57.434066Z","iopub.status.idle":"2021-12-20T14:13:57.449887Z","shell.execute_reply.started":"2021-12-20T14:13:57.434031Z","shell.execute_reply":"2021-12-20T14:13:57.449067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both can be seen to have the same format as expected. However, a large piece of outstanding information is how these different files will actually interact during the evaluation period. For example, if supplemental training data is intended to be used for training as the name implies, the final notebook will need to conduct both this training AND evaluation within the time limit. If this is done, there also would be no way to compare or choose manually whether to use a model with the supplemental train data or one only using the original train data. \n\nFor ease and less complication, it will probably be best to only use supplemental train as the starting input to any time series model rather than also use it for training.","metadata":{}}]}